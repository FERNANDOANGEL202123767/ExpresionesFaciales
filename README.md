# ğŸ˜Š API de AnÃ¡lisis de Emociones Faciales

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![Flask](https://img.shields.io/badge/Flask-2.0+-green.svg)](https://flask.palletsprojects.com/)
[![MediaPipe](https://img.shields.io/badge/MediaPipe-0.8+-orange.svg)](https://mediapipe.dev/)
[![OpenCV](https://img.shields.io/badge/OpenCV-4.5+-red.svg)](https://opencv.org/)
[![License](https://img.shields.io/badge/License-Educational%20Use-orange.svg)](#license)

> ğŸ”’ **ADVERTENCIA DE PRIVACIDAD**: Este proyecto es exclusivamente para fines educativos y de investigaciÃ³n. Maneja imÃ¡genes y datos faciales en un entorno seguro y respeta las normativas de privacidad.

## ğŸ“‹ DescripciÃ³n

Una **API web desarrollada con Flask** que combina tecnologÃ­as de computer vision y machine learning para analizar expresiones faciales en tiempo real. El sistema utiliza **MediaPipe** para la detecciÃ³n de puntos faciales clave y algoritmos de clasificaciÃ³n para identificar emociones humanas.

### âœ¨ CaracterÃ­sticas Principales

- ğŸ¯ **DetecciÃ³n de Puntos Faciales**: 68 puntos de referencia usando MediaPipe
- ğŸ˜„ **ClasificaciÃ³n de Emociones**: DetecciÃ³n de 5 emociones bÃ¡sicas
- ğŸ“¤ **Carga de ImÃ¡genes**: Soporte para mÃºltiples formatos de imagen
- ğŸ“Š **VisualizaciÃ³n de Datos**: AnÃ¡lisis del dataset con grÃ¡ficos interactivos
- ğŸŒ **API REST**: Endpoints simples y documentados
- ğŸ”§ **Interfaz Web**: Dashboard intuitivo para interactuar con la API
- ğŸš€ **ExposiciÃ³n PÃºblica**: IntegraciÃ³n opcional con ngrok

### ğŸ­ Emociones Detectadas

| EmociÃ³n | CÃ³digo | DescripciÃ³n |
|---------|--------|-------------|
| ğŸ˜¡ Ira | 0 | Expresiones de enojo y molestia |
| ğŸ˜¢ Tristeza | 1 | Estados de melancolÃ­a y dolor |
| ğŸ˜Š Felicidad | 2 | Expresiones de alegrÃ­a y satisfacciÃ³n |
| ğŸ˜® Sorpresa | 3 | Reacciones de asombro |
| ğŸ˜  Odio | 4 | Expresiones de disgusto intenso |

## ğŸ–¼ï¸ Capturas del Proyecto

### Interfaz Principal
![Main Interface](emotion/incio.png)
*Dashboard principal con opciones de carga y anÃ¡lisis de imÃ¡genes*

### AnÃ¡lisis de Emociones
![Emotion Analysis](emotion/analisis.png)
*Resultado del anÃ¡lisis mostrando puntos faciales y emociÃ³n detectada*

## ğŸ”§ Requisitos del Sistema

### Especificaciones TÃ©cnicas
- **Python**: 3.8 o superior
- **RAM**: MÃ­nimo 4GB (8GB recomendado)
- **CPU**: Procesador de doble nÃºcleo o superior
- **Almacenamiento**: ~2GB para dependencias y modelos
- **CÃ¡mara**: Opcional para anÃ¡lisis en tiempo real

### Entornos Recomendados
- ğŸ³ **Docker** (Recomendado)
- ğŸ–¥ï¸ **MÃ¡quina Virtual** (VirtualBox, VMware)
- ğŸ”’ **Entorno Aislado** sin acceso a datos sensibles

## ğŸ“¦ InstalaciÃ³n

### MÃ©todo 1: InstalaciÃ³n EstÃ¡ndar

```bash
# 1. Clonar el repositorio
git clone https://github.com/FERNANDOANGEL202123767/facial-emotion-api.git
cd facial-emotion-api

# 2. Crear entorno virtual
python -m venv venv

# 3. Activar entorno virtual
# Linux/macOS:
source venv/bin/activate
# Windows:
venv\Scripts\activate

# 4. Instalar dependencias
pip install -r requirements.txt

# 5. Verificar instalaciÃ³n
python -c "import cv2, mediapipe; print('âœ… InstalaciÃ³n exitosa')"
```

### MÃ©todo 2: Con Docker (Recomendado)

```dockerfile
# Dockerfile incluido en el proyecto
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
EXPOSE 5001

CMD ["python", "app.py"]
```

```bash
# Construir y ejecutar contenedor
docker build -t facial-emotion-api .
docker run -p 5001:5001 facial-emotion-api
```

## ğŸš€ Uso de la AplicaciÃ³n

### Iniciar el Servidor

```bash
# MÃ©todo bÃ¡sico
python app.py

# Con configuraciÃ³n personalizada
export FLASK_ENV=development
export PORT=5001
python app.py
```

**Acceso Local**: http://localhost:5001

## ğŸ”Œ API Endpoints

### 1. PÃ¡gina Principal
```http
GET /
```
**DescripciÃ³n**: Interfaz web principal  
**Respuesta**: PÃ¡gina HTML con formulario de carga

### 2. AnÃ¡lizar Imagen
```http
POST /analyze
Content-Type: multipart/form-data
```

**ParÃ¡metros**:
- `file`: Archivo de imagen (nueva)
- `existing_file`: Nombre de imagen existente

**Ejemplo con cURL**:
```bash
# Subir nueva imagen
curl -X POST -F "file=@mi_imagen.jpg" http://localhost:5001/analyze

# Usar imagen existente
curl -X POST -F "existing_file=imagen_guardada.jpg" http://localhost:5001/analyze
```


## ğŸ“Š Especificaciones TÃ©cnicas

### Formatos de Imagen Soportados
- **PNG** (Recomendado para calidad)
- **JPG/JPEG** (Optimizado para tamaÃ±o)
- **TamaÃ±o mÃ¡ximo**: 16 MB por imagen
- **ResoluciÃ³n recomendada**: 640x480 a 1920x1080

### Rendimiento
- **Tiempo de procesamiento**: ~0.3-1.5 segundos por imagen
- **PrecisiÃ³n del modelo**: ~85-92% segÃºn el dataset
- **Memoria utilizada**: ~200-500 MB durante procesamiento


### ValidaciÃ³n de Modelos
```bash
# Verificar precisiÃ³n del modelo
python utils/validate_model.py --dataset data/icml_face_data.csv
```

## ğŸ¤ Contribuciones

Â¡Las contribuciones son bienvenidas! Por favor sigue estos pasos:

### Proceso de ContribuciÃ³n

1. **Fork** el repositorio
2. **Crear rama** de funcionalidad:
   ```bash
   git checkout -b feature/nueva-funcionalidad
   ```
3. **Desarrollar** con tests incluidos
4. **Commit** con mensajes descriptivos:
   ```bash
   git commit -m "feat: agregar detecciÃ³n de micro-expresiones"
   ```
5. **Push** y crear **Pull Request**

### Ãreas de ContribuciÃ³n
- ğŸ§  Mejoras en algoritmos de detecciÃ³n
- ğŸ¨ Enhancements en la interfaz de usuario  
- ğŸ“Š Nuevos datasets y modelos
- ğŸ”§ Optimizaciones de rendimiento
- ğŸ“š DocumentaciÃ³n y tutoriales

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo licencia **Educational Use Only**.

```
MIT License - Educational Use

Copyright (c) 2025 Fernando Angel

```

## ğŸ‘¨â€ğŸ’» Contacto y Soporte

**Desarrollador Principal**: Fernando Angel  
**GitHub**: [@FERNANDOANGEL202123767](https://github.com/FERNANDOANGEL202123767)  

### ğŸ†˜ Obtener Ayuda

1. **Issues**: [GitHub Issues](https://github.com/FERNANDOANGEL202123767/facial-emotion-api/issues)
2. **Discusiones**: [GitHub Discussions](https://github.com/FERNANDOANGEL202123767/facial-emotion-api/discussions)

### ğŸ“š Recursos Adicionales

- [DocumentaciÃ³n de MediaPipe](https://mediapipe.dev/)
- [GuÃ­a de OpenCV](https://opencv.org/documentation/)
- [Tutorial de Flask](https://flask.palletsprojects.com/tutorial/)
- [Curso de Computer Vision](https://www.coursera.org/learn/computer-vision-basics)

---


**ğŸŒŸ Si este proyecto te fue Ãºtil, considera darle una estrella en GitHub ğŸŒŸ**

**Construido con â¤ï¸ para la investigaciÃ³n en Computer Vision y AI**

[â¬†ï¸ Volver al inicio](#-api-de-anÃ¡lisis-de-emociones-faciales)
